{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "882ebcf0",
   "metadata": {},
   "source": [
    "# Modelo Predictivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5d0ed65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "antiguedad_anos  Î² = +0.299\n",
      "satisfaccion     Î² = -1.011\n",
      "salario_nivel    Î² = -0.516\n",
      "promociones      Î² = +0.261\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "# â”€â”€ 1) Datos de ejemplo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df = pd.DataFrame({\n",
    "    \"antiguedad_anos\":  [1, 3, 8, 2, 5, 4, 10, 7],\n",
    "    \"satisfaccion\":     [0.4, 0.9, 0.2, 0.7, 0.8, 0.6, 0.3, 0.5],\n",
    "    \"salario_nivel\":    [1, 2, 3, 2, 2, 2, 3, 1],      # 1-bajo / 3-alto\n",
    "    \"promociones\":      [0, 1, 2, 0, 1, 1, 3, 2],\n",
    "    \"renuncia\":         [1, 0, 1, 0, 0, 0, 1, 1]       # 1=se fue, 0=se quedÃ³\n",
    "})\n",
    "\n",
    "X = df.drop(\"renuncia\", axis=1)\n",
    "y = df[\"renuncia\"]\n",
    "\n",
    "# â”€â”€ 2) Split y escalado â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,\n",
    "                                                    random_state=42, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# â”€â”€ 3) Entrenar modelo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# â”€â”€ 4) Evaluar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "y_prob = logreg.predict_proba(X_test_scaled)[:, 1]\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# â”€â”€ 5) InterpretaciÃ³n rÃ¡pida: coeficientes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "for name, coef in zip(X.columns, logreg.coef_[0]):\n",
    "    print(f\"{name:15s}  Î² = {coef:+.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b893703d",
   "metadata": {},
   "source": [
    "P(Renuncia) = 1 / (1 + e^-(Î²0 + Î²1*AÃ±os + Î²2*Salario + Î²3*SatisfacciÃ³n + ...))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2809323a",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2428a51",
   "metadata": {},
   "source": [
    "# AnÃ¡lisis Paso a Paso del Modelo de PredicciÃ³n de Renuncia\n",
    "Este cÃ³digo implementa un modelo de Random Forest para predecir la renuncia de empleados basado en varias caracterÃ­sticas. Vamos a desglosarlo:\n",
    "\n",
    "1) PreparaciÃ³n de Datos\n",
    "Se crea un DataFrame con 8 empleados y 9 variables:\n",
    "\n",
    "Variables predictoras: antigÃ¼edad, satisfacciÃ³n, nivel salarial, promociones, horas extra, ausencias, distancia al trabajo, formaciÃ³n\n",
    "\n",
    "Variable objetivo: renuncia (1=SÃ­, 0=No)\n",
    "\n",
    "2) DivisiÃ³n de Datos\n",
    "Se separa en conjuntos de entrenamiento (75%) y prueba (25%)\n",
    "\n",
    "stratify=y asegura proporciÃ³n similar de renuncias en ambos conjuntos\n",
    "\n",
    "Resultado: 6 muestras entrenamiento, 2 muestras prueba\n",
    "\n",
    "3) Entrenamiento con Grid Search\n",
    "Se usa Random Forest Classifier\n",
    "\n",
    "* BÃºsqueda de hiperparÃ¡metros con GridSearchCV:\n",
    "\n",
    "    * Prueba 200 y 400 Ã¡rboles (n_estimators)\n",
    "\n",
    "    * Prueba profundidades mÃ¡xima: None (sin lÃ­mite), 4 y 6 niveles\n",
    "\n",
    "    1. Â¿QuÃ© es Grid Search?\n",
    "        Grid Search es una tÃ©cnica de optimizaciÃ³n de hiperparÃ¡metros que prueba todas las combinaciones posibles de valores dados para encontrar la mejor configuraciÃ³n del modelo.\n",
    "\n",
    "        HiperparÃ¡metros: Son configuraciones del modelo que no se aprenden de los datos, sino que se definen antes del entrenamiento (ej: nÃºmero de Ã¡rboles, profundidad mÃ¡xima).\n",
    "\n",
    "        GridSearchCV prueba todas las combinaciones posibles usando validaciÃ³n cruzada (CV) para evitar sobreajuste.\n",
    "    \n",
    "    2. ConfiguraciÃ³n del Random Forest\n",
    "        El modelo base es un RandomForestClassifier, que funciona creando mÃºltiples Ã¡rboles de decisiÃ³n y combinando sus resultados para mejorar la precisiÃ³n y reducir el sobreajuste.\n",
    "\n",
    "        HiperparÃ¡metros Optimizados en este Ejemplo:\n",
    "        \n",
    "        * n_estimators: NÃºmero de Ã¡rboles en el bosque.\n",
    "\n",
    "            * Valores probados: [200, 400] (se prueban bosques con 200 y 400 Ã¡rboles).\n",
    "\n",
    "            * MÃ¡s Ã¡rboles mejoran la estabilidad, pero aumentan el costo computacional.\n",
    "\n",
    "        * max_depth: Profundidad mÃ¡xima de cada Ã¡rbol.\n",
    "\n",
    "            * Valores probados: [None, 4, 6]\n",
    "\n",
    "            * None: Sin lÃ­mite (los Ã¡rboles crecen hasta que todas las hojas son puras o hasta min_samples_split).\n",
    "\n",
    "            * 4 y 6: Limita la profundidad para evitar sobreajuste (Ã¡rboles mÃ¡s simples).\n",
    "    3. Â¿CÃ³mo funciona GridSearchCV?\n",
    "        El proceso es el siguiente:\n",
    "\n",
    "        1. Define el espacio de bÃºsqueda (todas las combinaciones posibles):\n",
    "\n",
    "            * n_estimators=200, max_depth=None\n",
    "\n",
    "            * n_estimators=200, max_depth=4\n",
    "\n",
    "            * n_estimators=200, max_depth=6\n",
    "\n",
    "            * n_estimators=400, max_depth=None\n",
    "\n",
    "            * n_estimators=400, max_depth=4\n",
    "\n",
    "            * n_estimators=400, max_depth=6\n",
    "            â†’ Total: 6 combinaciones.\n",
    "\n",
    "        2. ValidaciÃ³n Cruzada (CV=3):\n",
    "\n",
    "            * Divide los datos de entrenamiento en 3 partes (folds).\n",
    "\n",
    "            * Entrena el modelo en 2 folds y evalÃºa en 1 fold, rotando hasta probar todas las combinaciones.\n",
    "            \n",
    "            * Repite esto para cada combinaciÃ³n de hiperparÃ¡metros.\n",
    "\n",
    "        3. SelecciÃ³n del mejor modelo:\n",
    "\n",
    "            * Usa AUC (Area Under the ROC Curve) como mÃ©trica de evaluaciÃ³n (ideal para problemas de clasificaciÃ³n desbalanceada).\n",
    "\n",
    "            * Elige la combinaciÃ³n que maximiza el AUC promedio en validaciÃ³n cruzada.\n",
    "        4. Resultados del Grid Search\n",
    "            En este caso, el mejor modelo fue uno de los probados (no sabemos cuÃ¡l exactamente sin ver grid.best_params_), pero sabemos que:\n",
    "\n",
    "            * AUC = 1.0 (rendimiento perfecto en los datos de prueba).\n",
    "\n",
    "            * Esto sugiere que alguna combinaciÃ³n de n_estimators y max_depth logrÃ³ un ajuste perfecto (aunque podrÃ­a ser sobreajuste debido al pequeÃ±o dataset).\n",
    "\n",
    "        5. Â¿Por quÃ© usar Grid Search?\n",
    "            * Evita el \"ensayo y error\" manual de hiperparÃ¡metros.\n",
    "\n",
    "            * Optimiza automÃ¡ticamente el modelo para la mÃ©trica deseada (en este caso, AUC).\n",
    "\n",
    "            * Reduce el riesgo de sobreajuste al usar validaciÃ³n cruzada.\n",
    "        â¡ï¸ Posibles Mejoras:\n",
    "            * Probar mÃ¡s valores (ej: n_estimators=[50, 100, 200, 400]).\n",
    "\n",
    "            * Incluir otros hiperparÃ¡metros como min_samples_split, max_features, etc.\n",
    "\n",
    "            * Usar RandomizedSearchCV si el espacio de bÃºsqueda es muy grande (muestra combinaciones aleatorias en lugar de todas).\n",
    "\n",
    "        âœ… ConclusiÃ³n\n",
    "        El Grid Search con Random Forest permite encontrar la mejor combinaciÃ³n de hiperparÃ¡metros de manera sistemÃ¡tica, mejorando el rendimiento del modelo. En este caso, el resultado fue perfecto (AUC=1.0), pero en un escenario real con mÃ¡s datos, el proceso ayudarÃ­a a equilibrar precisiÃ³n y generalizaciÃ³n.\n",
    "\n",
    "Se selecciona el mejor modelo segÃºn AUC (Area Under Curve)\n",
    "\n",
    "4) EvaluaciÃ³n del Modelo\n",
    "Resultados Obtenidos:\n",
    "AUC: 1.0 (Perfecto, mÃ¡xima capacidad de discriminaciÃ³n)\n",
    "\n",
    "Classification Report:\n",
    "\n",
    "Precision, Recall y F1-score todos en 1.0 (perfectos)\n",
    "\n",
    "El modelo acertÃ³ en ambas predicciones de prueba\n",
    "\n",
    "InterpretaciÃ³n:\n",
    "El modelo tuvo rendimiento perfecto en este pequeÃ±o conjunto de prueba\n",
    "\n",
    "Sin embargo, con solo 2 muestras de prueba, estos resultados no son estadÃ­sticamente significativos\n",
    "\n",
    "En un escenario real necesitarÃ­amos mÃ¡s datos para evaluaciÃ³n confiable\n",
    "\n",
    "5) Importancia de Variables\n",
    "El cÃ³digo calcula pero no muestra los valores especÃ­ficos de importancia\n",
    "\n",
    "Estas mostrarÃ­an quÃ© variables contribuyeron mÃ¡s a las predicciones (ej: satisfacciÃ³n, antigÃ¼edad)\n",
    "\n",
    "Limitaciones a Considerar:\n",
    "TamaÃ±o de muestra extremadamente pequeÃ±o (8 registros)\n",
    "\n",
    "EvaluaciÃ³n en solo 2 muestras de prueba\n",
    "\n",
    "Posible sobreajuste (overfitting) debido a lo anterior\n",
    "\n",
    "Resultados perfectos suelen ser sospechosos en casos reales\n",
    "\n",
    "Recomendaciones para Mejora:\n",
    "Obtener mÃ¡s datos (cientos o miles de registros)\n",
    "\n",
    "ValidaciÃ³n cruzada mÃ¡s robusta\n",
    "\n",
    "Considerar otras mÃ©tricas ademÃ¡s de AUC\n",
    "\n",
    "Explorar balance de clases (Â¿proporciÃ³n de renuncias?)\n",
    "\n",
    "En resumen, este es un ejemplo didÃ¡ctico que muestra el flujo completo de un modelo de machine learning, pero los resultados perfectos reflejan las limitaciones del pequeÃ±o conjunto de datos mÃ¡s que un rendimiento realista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d91afacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### ğŸ“Š Importancia de Variables"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dias_ausencia       0.225694\n",
       "satisfaccion        0.206250\n",
       "horas_extra_mes     0.131641\n",
       "salario_nivel       0.108854\n",
       "distancia_km        0.106597\n",
       "antiguedad_anos     0.080990\n",
       "formacion_cursos    0.072786\n",
       "promociones         0.067188\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ğŸ“ˆ MÃ©tricas de EvaluaciÃ³n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**AUC:** `1.0000`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Classification Report:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "# â”€â”€ 1) Datos con mÃ¡s riqueza â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df = pd.DataFrame({\n",
    "    \"antiguedad_anos\":      [1, 3, 8, 2, 5, 4, 10, 7],\n",
    "    \"satisfaccion\":         [0.4, 0.9, 0.2, 0.7, 0.8, 0.6, 0.3, 0.5],\n",
    "    \"salario_nivel\":        [1, 2, 3, 2, 2, 2, 3, 1],\n",
    "    \"promociones\":          [0, 1, 2, 0, 1, 1, 3, 2],\n",
    "    \"horas_extra_mes\":      [10, 2, 5, 8, 1, 0, 12, 9],\n",
    "    \"dias_ausencia\":        [2, 0, 4, 1, 0, 0, 5, 3],\n",
    "    \"distancia_km\":         [8, 15, 2, 25, 12, 9, 3, 30],\n",
    "    \"formacion_cursos\":     [3, 5, 1, 4, 6, 2, 0, 2],\n",
    "    \"renuncia\":             [1, 0, 1, 0, 0, 0, 1, 1]\n",
    "})\n",
    "\n",
    "X = df.drop(\"renuncia\", axis=1)\n",
    "y = df[\"renuncia\"]\n",
    "\n",
    "# â”€â”€ 2) Split â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,\n",
    "                                                    random_state=42, stratify=y)\n",
    "\n",
    "# â”€â”€ 3) Entrenar con bÃºsqueda de hiperparÃ¡metros â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\"n_estimators\": [200, 400],\n",
    "              \"max_depth\": [None, 4, 6]}\n",
    "grid = GridSearchCV(rf, param_grid, cv=3, scoring=\"roc_auc\")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid.best_estimator_\n",
    "\n",
    "# â”€â”€ 4) Evaluar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "y_pred = best_rf.predict(X_test)\n",
    "y_prob = best_rf.predict_proba(X_test)[:, 1]\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# â”€â”€ 5) Importancia de variables â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "importances = pd.Series(best_rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(\"### ğŸ“Š Importancia de Variables\"))\n",
    "display(importances)\n",
    "\n",
    "display(Markdown(\"### ğŸ“ˆ MÃ©tricas de EvaluaciÃ³n\"))\n",
    "display(Markdown(f\"**AUC:** `{roc_auc_score(y_test, y_prob):.4f}`\"))\n",
    "display(Markdown(\"**Classification Report:**\"))\n",
    "print(classification_report(y_test, y_pred))  # Se imprime normal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9841b6fd",
   "metadata": {},
   "source": [
    "# InterpretaciÃ³n Detallada de los Resultados del Modelo\n",
    "\n",
    "## AnÃ¡lisis de la Importancia de Variables\n",
    "\n",
    "El modelo de Random Forest ha asignado las siguientes importancias a cada variable predictora:\n",
    "\n",
    "| Variable           | Importancia | InterpretaciÃ³n |\n",
    "|--------------------|-------------|----------------|\n",
    "| dias_ausencia      | 0.226       | La variable mÃ¡s importante, sugiere que las ausencias laborales son el principal predictor de renuncia. |\n",
    "| satisfaccion       | 0.206       | El segundo factor mÃ¡s relevante, indica que empleados menos satisfechos tienen mayor probabilidad de renunciar |\n",
    "| horas_extra_mes    | 0.132       | Las horas extras muestran un impacto moderado en la decisiÃ³n de renuncia. |\n",
    "| salario_nivel      | 0.109       | El nivel salarial tiene una influencia perceptible pero menor que los factores anteriores. |\n",
    "| distancia_km       | 0.107       | La distancia al trabajo aparece como un factor relevante pero no determinante. |\n",
    "| antiguedad_anos    | 0.081       | La antigÃ¼edad en la empresa tiene un impacto relativamente bajo. |\n",
    "| formacion_cursos   | 0.073       | La formaciÃ³n recibida muestra una influencia menor |\n",
    "| promociones        | 0.067       | Las promociones aparecen como el factor menos influyente. |\n",
    "\n",
    "**InterpretaciÃ³n clave**: Las polÃ­ticas para reducir ausencias y mejorar la satisfacciÃ³n laboral serÃ­an las mÃ¡s efectivas para retener empleados.\n",
    "\n",
    "## EvaluaciÃ³n del Rendimiento del Modelo\n",
    "\n",
    "### MÃ©trica AUC (Area Under Curve)\n",
    "- **AUC = 1.0** (perfecto)\n",
    "- **Significado**: ClasificaciÃ³n correcta del 100% de casos\n",
    "- **Contexto**: Con solo 2 muestras de prueba, interpretar con cautela\n",
    "\n",
    "### Classification Report\n",
    "\n",
    "| MÃ©trica       | Clase 0 (No renuncia) | Clase 1 (Renuncia) |\n",
    "|---------------|----------------------|-------------------|\n",
    "| Precision     | 1.00                 | 1.00              |\n",
    "| Recall        | 1.00                 | 1.00              |\n",
    "| F1-score      | 1.00                 | 1.00              |\n",
    "| Support       | 1 caso               | 1 caso            |\n",
    "\n",
    "**InterpretaciÃ³n**:\n",
    "- Todas las mÃ©tricas muestran rendimiento perfecto\n",
    "- Accuracy del 100% en el conjunto de prueba\n",
    "\n",
    "## Limitaciones y Consideraciones\n",
    "\n",
    "1. **TamaÃ±o de muestra pequeÃ±o**:\n",
    "   - 8 casos entrenamiento, 2 pruebas\n",
    "   - Riesgo de sobreajuste (overfitting)\n",
    "\n",
    "2. **ValidaciÃ³n adicional necesaria**:\n",
    "   - Requiere mÃ¡s datos para confirmaciÃ³n\n",
    "   - ValidaciÃ³n cruzada recomendable\n",
    "\n",
    "3. **Contexto empresarial**:\n",
    "   - CorrelaciÃ³n â‰  causalidad\n",
    "   - Posibles variables omitidas\n",
    "\n",
    "## Recomendaciones de AcciÃ³n\n",
    "\n",
    "```python\n",
    "# PseudocÃ³digo para implementaciÃ³n prÃ¡ctica\n",
    "def recomendaciones_HR():\n",
    "    acciones = [\n",
    "        \"Recolectar mÃ¡s datos (100+ empleados)\",\n",
    "        \"Implementar programas anti-ausentismo\",\n",
    "        \"Mejorar satisfacciÃ³n laboral\",\n",
    "        \"Revisar polÃ­ticas de horas extras\",\n",
    "        \"Monitoreo continuo con nuevos datos\",\n",
    "        \"Validar con estudios cualitativos\"\n",
    "    ]\n",
    "    return acciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffecf9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
