{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "882ebcf0",
   "metadata": {},
   "source": [
    "# Modelo Predictivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5d0ed65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "antiguedad_anos  β = +0.299\n",
      "satisfaccion     β = -1.011\n",
      "salario_nivel    β = -0.516\n",
      "promociones      β = +0.261\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "# ── 1) Datos de ejemplo ──────────────────────────────────────────────\n",
    "df = pd.DataFrame({\n",
    "    \"antiguedad_anos\":  [1, 3, 8, 2, 5, 4, 10, 7],\n",
    "    \"satisfaccion\":     [0.4, 0.9, 0.2, 0.7, 0.8, 0.6, 0.3, 0.5],\n",
    "    \"salario_nivel\":    [1, 2, 3, 2, 2, 2, 3, 1],      # 1-bajo / 3-alto\n",
    "    \"promociones\":      [0, 1, 2, 0, 1, 1, 3, 2],\n",
    "    \"renuncia\":         [1, 0, 1, 0, 0, 0, 1, 1]       # 1=se fue, 0=se quedó\n",
    "})\n",
    "\n",
    "X = df.drop(\"renuncia\", axis=1)\n",
    "y = df[\"renuncia\"]\n",
    "\n",
    "# ── 2) Split y escalado ───────────────────────────────────────────────\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,\n",
    "                                                    random_state=42, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# ── 3) Entrenar modelo ────────────────────────────────────────────────\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ── 4) Evaluar ────────────────────────────────────────────────────────\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "y_prob = logreg.predict_proba(X_test_scaled)[:, 1]\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ── 5) Interpretación rápida: coeficientes ────────────────────────────\n",
    "for name, coef in zip(X.columns, logreg.coef_[0]):\n",
    "    print(f\"{name:15s}  β = {coef:+.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b893703d",
   "metadata": {},
   "source": [
    "P(Renuncia) = 1 / (1 + e^-(β0 + β1*Años + β2*Salario + β3*Satisfacción + ...))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2809323a",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2428a51",
   "metadata": {},
   "source": [
    "# Análisis Paso a Paso del Modelo de Predicción de Renuncia\n",
    "Este código implementa un modelo de Random Forest para predecir la renuncia de empleados basado en varias características. Vamos a desglosarlo:\n",
    "\n",
    "1) Preparación de Datos\n",
    "Se crea un DataFrame con 8 empleados y 9 variables:\n",
    "\n",
    "Variables predictoras: antigüedad, satisfacción, nivel salarial, promociones, horas extra, ausencias, distancia al trabajo, formación\n",
    "\n",
    "Variable objetivo: renuncia (1=Sí, 0=No)\n",
    "\n",
    "2) División de Datos\n",
    "Se separa en conjuntos de entrenamiento (75%) y prueba (25%)\n",
    "\n",
    "stratify=y asegura proporción similar de renuncias en ambos conjuntos\n",
    "\n",
    "Resultado: 6 muestras entrenamiento, 2 muestras prueba\n",
    "\n",
    "3) Entrenamiento con Grid Search\n",
    "Se usa Random Forest Classifier\n",
    "\n",
    "* Búsqueda de hiperparámetros con GridSearchCV:\n",
    "\n",
    "    * Prueba 200 y 400 árboles (n_estimators)\n",
    "\n",
    "    * Prueba profundidades máxima: None (sin límite), 4 y 6 niveles\n",
    "\n",
    "    1. ¿Qué es Grid Search?\n",
    "        Grid Search es una técnica de optimización de hiperparámetros que prueba todas las combinaciones posibles de valores dados para encontrar la mejor configuración del modelo.\n",
    "\n",
    "        Hiperparámetros: Son configuraciones del modelo que no se aprenden de los datos, sino que se definen antes del entrenamiento (ej: número de árboles, profundidad máxima).\n",
    "\n",
    "        GridSearchCV prueba todas las combinaciones posibles usando validación cruzada (CV) para evitar sobreajuste.\n",
    "    \n",
    "    2. Configuración del Random Forest\n",
    "        El modelo base es un RandomForestClassifier, que funciona creando múltiples árboles de decisión y combinando sus resultados para mejorar la precisión y reducir el sobreajuste.\n",
    "\n",
    "        Hiperparámetros Optimizados en este Ejemplo:\n",
    "        \n",
    "        * n_estimators: Número de árboles en el bosque.\n",
    "\n",
    "            * Valores probados: [200, 400] (se prueban bosques con 200 y 400 árboles).\n",
    "\n",
    "            * Más árboles mejoran la estabilidad, pero aumentan el costo computacional.\n",
    "\n",
    "        * max_depth: Profundidad máxima de cada árbol.\n",
    "\n",
    "            * Valores probados: [None, 4, 6]\n",
    "\n",
    "            * None: Sin límite (los árboles crecen hasta que todas las hojas son puras o hasta min_samples_split).\n",
    "\n",
    "            * 4 y 6: Limita la profundidad para evitar sobreajuste (árboles más simples).\n",
    "    3. ¿Cómo funciona GridSearchCV?\n",
    "        El proceso es el siguiente:\n",
    "\n",
    "        1. Define el espacio de búsqueda (todas las combinaciones posibles):\n",
    "\n",
    "            * n_estimators=200, max_depth=None\n",
    "\n",
    "            * n_estimators=200, max_depth=4\n",
    "\n",
    "            * n_estimators=200, max_depth=6\n",
    "\n",
    "            * n_estimators=400, max_depth=None\n",
    "\n",
    "            * n_estimators=400, max_depth=4\n",
    "\n",
    "            * n_estimators=400, max_depth=6\n",
    "            → Total: 6 combinaciones.\n",
    "\n",
    "        2. Validación Cruzada (CV=3):\n",
    "\n",
    "            * Divide los datos de entrenamiento en 3 partes (folds).\n",
    "\n",
    "            * Entrena el modelo en 2 folds y evalúa en 1 fold, rotando hasta probar todas las combinaciones.\n",
    "            \n",
    "            * Repite esto para cada combinación de hiperparámetros.\n",
    "\n",
    "        3. Selección del mejor modelo:\n",
    "\n",
    "            * Usa AUC (Area Under the ROC Curve) como métrica de evaluación (ideal para problemas de clasificación desbalanceada).\n",
    "\n",
    "            * Elige la combinación que maximiza el AUC promedio en validación cruzada.\n",
    "        4. Resultados del Grid Search\n",
    "            En este caso, el mejor modelo fue uno de los probados (no sabemos cuál exactamente sin ver grid.best_params_), pero sabemos que:\n",
    "\n",
    "            * AUC = 1.0 (rendimiento perfecto en los datos de prueba).\n",
    "\n",
    "            * Esto sugiere que alguna combinación de n_estimators y max_depth logró un ajuste perfecto (aunque podría ser sobreajuste debido al pequeño dataset).\n",
    "\n",
    "        5. ¿Por qué usar Grid Search?\n",
    "            * Evita el \"ensayo y error\" manual de hiperparámetros.\n",
    "\n",
    "            * Optimiza automáticamente el modelo para la métrica deseada (en este caso, AUC).\n",
    "\n",
    "            * Reduce el riesgo de sobreajuste al usar validación cruzada.\n",
    "        ➡️ Posibles Mejoras:\n",
    "            * Probar más valores (ej: n_estimators=[50, 100, 200, 400]).\n",
    "\n",
    "            * Incluir otros hiperparámetros como min_samples_split, max_features, etc.\n",
    "\n",
    "            * Usar RandomizedSearchCV si el espacio de búsqueda es muy grande (muestra combinaciones aleatorias en lugar de todas).\n",
    "\n",
    "        ✅ Conclusión\n",
    "        El Grid Search con Random Forest permite encontrar la mejor combinación de hiperparámetros de manera sistemática, mejorando el rendimiento del modelo. En este caso, el resultado fue perfecto (AUC=1.0), pero en un escenario real con más datos, el proceso ayudaría a equilibrar precisión y generalización.\n",
    "\n",
    "Se selecciona el mejor modelo según AUC (Area Under Curve)\n",
    "\n",
    "4) Evaluación del Modelo\n",
    "Resultados Obtenidos:\n",
    "AUC: 1.0 (Perfecto, máxima capacidad de discriminación)\n",
    "\n",
    "Classification Report:\n",
    "\n",
    "Precision, Recall y F1-score todos en 1.0 (perfectos)\n",
    "\n",
    "El modelo acertó en ambas predicciones de prueba\n",
    "\n",
    "Interpretación:\n",
    "El modelo tuvo rendimiento perfecto en este pequeño conjunto de prueba\n",
    "\n",
    "Sin embargo, con solo 2 muestras de prueba, estos resultados no son estadísticamente significativos\n",
    "\n",
    "En un escenario real necesitaríamos más datos para evaluación confiable\n",
    "\n",
    "5) Importancia de Variables\n",
    "El código calcula pero no muestra los valores específicos de importancia\n",
    "\n",
    "Estas mostrarían qué variables contribuyeron más a las predicciones (ej: satisfacción, antigüedad)\n",
    "\n",
    "Limitaciones a Considerar:\n",
    "Tamaño de muestra extremadamente pequeño (8 registros)\n",
    "\n",
    "Evaluación en solo 2 muestras de prueba\n",
    "\n",
    "Posible sobreajuste (overfitting) debido a lo anterior\n",
    "\n",
    "Resultados perfectos suelen ser sospechosos en casos reales\n",
    "\n",
    "Recomendaciones para Mejora:\n",
    "Obtener más datos (cientos o miles de registros)\n",
    "\n",
    "Validación cruzada más robusta\n",
    "\n",
    "Considerar otras métricas además de AUC\n",
    "\n",
    "Explorar balance de clases (¿proporción de renuncias?)\n",
    "\n",
    "En resumen, este es un ejemplo didáctico que muestra el flujo completo de un modelo de machine learning, pero los resultados perfectos reflejan las limitaciones del pequeño conjunto de datos más que un rendimiento realista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d91afacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 📊 Importancia de Variables"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dias_ausencia       0.225694\n",
       "satisfaccion        0.206250\n",
       "horas_extra_mes     0.131641\n",
       "salario_nivel       0.108854\n",
       "distancia_km        0.106597\n",
       "antiguedad_anos     0.080990\n",
       "formacion_cursos    0.072786\n",
       "promociones         0.067188\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### 📈 Métricas de Evaluación"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**AUC:** `1.0000`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Classification Report:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "# ── 1) Datos con más riqueza ──────────────────────────────────────────\n",
    "df = pd.DataFrame({\n",
    "    \"antiguedad_anos\":      [1, 3, 8, 2, 5, 4, 10, 7],\n",
    "    \"satisfaccion\":         [0.4, 0.9, 0.2, 0.7, 0.8, 0.6, 0.3, 0.5],\n",
    "    \"salario_nivel\":        [1, 2, 3, 2, 2, 2, 3, 1],\n",
    "    \"promociones\":          [0, 1, 2, 0, 1, 1, 3, 2],\n",
    "    \"horas_extra_mes\":      [10, 2, 5, 8, 1, 0, 12, 9],\n",
    "    \"dias_ausencia\":        [2, 0, 4, 1, 0, 0, 5, 3],\n",
    "    \"distancia_km\":         [8, 15, 2, 25, 12, 9, 3, 30],\n",
    "    \"formacion_cursos\":     [3, 5, 1, 4, 6, 2, 0, 2],\n",
    "    \"renuncia\":             [1, 0, 1, 0, 0, 0, 1, 1]\n",
    "})\n",
    "\n",
    "X = df.drop(\"renuncia\", axis=1)\n",
    "y = df[\"renuncia\"]\n",
    "\n",
    "# ── 2) Split ──────────────────────────────────────────────────────────\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,\n",
    "                                                    random_state=42, stratify=y)\n",
    "\n",
    "# ── 3) Entrenar con búsqueda de hiperparámetros ───────────────────────\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\"n_estimators\": [200, 400],\n",
    "              \"max_depth\": [None, 4, 6]}\n",
    "grid = GridSearchCV(rf, param_grid, cv=3, scoring=\"roc_auc\")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid.best_estimator_\n",
    "\n",
    "# ── 4) Evaluar ────────────────────────────────────────────────────────\n",
    "y_pred = best_rf.predict(X_test)\n",
    "y_prob = best_rf.predict_proba(X_test)[:, 1]\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ── 5) Importancia de variables ───────────────────────────────────────\n",
    "importances = pd.Series(best_rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(\"### 📊 Importancia de Variables\"))\n",
    "display(importances)\n",
    "\n",
    "display(Markdown(\"### 📈 Métricas de Evaluación\"))\n",
    "display(Markdown(f\"**AUC:** `{roc_auc_score(y_test, y_prob):.4f}`\"))\n",
    "display(Markdown(\"**Classification Report:**\"))\n",
    "print(classification_report(y_test, y_pred))  # Se imprime normal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9841b6fd",
   "metadata": {},
   "source": [
    "# Interpretación Detallada de los Resultados del Modelo\n",
    "\n",
    "## Análisis de la Importancia de Variables\n",
    "\n",
    "El modelo de Random Forest ha asignado las siguientes importancias a cada variable predictora:\n",
    "\n",
    "| Variable           | Importancia | Interpretación |\n",
    "|--------------------|-------------|----------------|\n",
    "| dias_ausencia      | 0.226       | La variable más importante, sugiere que las ausencias laborales son el principal predictor de renuncia. |\n",
    "| satisfaccion       | 0.206       | El segundo factor más relevante, indica que empleados menos satisfechos tienen mayor probabilidad de renunciar |\n",
    "| horas_extra_mes    | 0.132       | Las horas extras muestran un impacto moderado en la decisión de renuncia. |\n",
    "| salario_nivel      | 0.109       | El nivel salarial tiene una influencia perceptible pero menor que los factores anteriores. |\n",
    "| distancia_km       | 0.107       | La distancia al trabajo aparece como un factor relevante pero no determinante. |\n",
    "| antiguedad_anos    | 0.081       | La antigüedad en la empresa tiene un impacto relativamente bajo. |\n",
    "| formacion_cursos   | 0.073       | La formación recibida muestra una influencia menor |\n",
    "| promociones        | 0.067       | Las promociones aparecen como el factor menos influyente. |\n",
    "\n",
    "**Interpretación clave**: Las políticas para reducir ausencias y mejorar la satisfacción laboral serían las más efectivas para retener empleados.\n",
    "\n",
    "## Evaluación del Rendimiento del Modelo\n",
    "\n",
    "### Métrica AUC (Area Under Curve)\n",
    "- **AUC = 1.0** (perfecto)\n",
    "- **Significado**: Clasificación correcta del 100% de casos\n",
    "- **Contexto**: Con solo 2 muestras de prueba, interpretar con cautela\n",
    "\n",
    "### Classification Report\n",
    "\n",
    "| Métrica       | Clase 0 (No renuncia) | Clase 1 (Renuncia) |\n",
    "|---------------|----------------------|-------------------|\n",
    "| Precision     | 1.00                 | 1.00              |\n",
    "| Recall        | 1.00                 | 1.00              |\n",
    "| F1-score      | 1.00                 | 1.00              |\n",
    "| Support       | 1 caso               | 1 caso            |\n",
    "\n",
    "**Interpretación**:\n",
    "- Todas las métricas muestran rendimiento perfecto\n",
    "- Accuracy del 100% en el conjunto de prueba\n",
    "\n",
    "## Limitaciones y Consideraciones\n",
    "\n",
    "1. **Tamaño de muestra pequeño**:\n",
    "   - 8 casos entrenamiento, 2 pruebas\n",
    "   - Riesgo de sobreajuste (overfitting)\n",
    "\n",
    "2. **Validación adicional necesaria**:\n",
    "   - Requiere más datos para confirmación\n",
    "   - Validación cruzada recomendable\n",
    "\n",
    "3. **Contexto empresarial**:\n",
    "   - Correlación ≠ causalidad\n",
    "   - Posibles variables omitidas\n",
    "\n",
    "## Recomendaciones de Acción\n",
    "\n",
    "```python\n",
    "# Pseudocódigo para implementación práctica\n",
    "def recomendaciones_HR():\n",
    "    acciones = [\n",
    "        \"Recolectar más datos (100+ empleados)\",\n",
    "        \"Implementar programas anti-ausentismo\",\n",
    "        \"Mejorar satisfacción laboral\",\n",
    "        \"Revisar políticas de horas extras\",\n",
    "        \"Monitoreo continuo con nuevos datos\",\n",
    "        \"Validar con estudios cualitativos\"\n",
    "    ]\n",
    "    return acciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffecf9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
